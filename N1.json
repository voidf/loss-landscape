{"model1": "tn10/vgg9_sgd_lr=0.1_bs=128_wd=0.0005_mom=0.9_save_epoch=1/model_300.t7", "model2": "tn09/vgg9_sgd_lr=0.1_bs=128_wd=0.0005_mom=0.9_save_epoch=1/model_300.t7", "method": "neb"}
{"model1": "tn10/vgg9_sgd_lr=0.1_bs=128_wd=0.0005_mom=0.9_save_epoch=1/model_300.t7", "model2": "tn09/vgg9_sgd_lr=0.1_bs=128_wd=0.0005_mom=0.9_save_epoch=1/model_300.t7", "method": "neb"}
{"model1": "R56_01/resnet56_sgd_lr=0.1_bs=128_wd=0.0005_mom=0.9_save_epoch=1/model_300.t7", "model2": "R56_02/resnet56_sgd_lr=0.1_bs=128_wd=0.0005_mom=0.9_save_epoch=1/model_300.t7", "method": "neb"}
step 0, loss: 2.4418859481811523
step 0, loss: 2.410024642944336
step 0, loss: 2.4622411727905273
step 0, loss: 2.4552299976348877
step 0, loss: 2.416292428970337
step 0, loss: 2.4775924682617188
step 2, loss: 2.185375213623047
step 12, loss: 1.9483925104141235
step 39, loss: 1.7378506660461426
step 97, loss: 1.5338810682296753
step 0, loss: 2.4011688232421875
step 4, loss: 2.0303993225097656
step 27, loss: 1.7988989353179932
step 90, loss: 1.609999179840088
step 123, loss: 1.4466146230697632
step 193, loss: 1.301250696182251
step 289, loss: 1.1514919996261597
step 351, loss: 1.0323671102523804
step 460, loss: 0.9053356647491455
step 647, loss: 0.8140150308609009
step 766, loss: 0.7140674591064453
step 1091, loss: 0.6343587040901184
step 1294, loss: 0.5681657195091248
step 1624, loss: 0.5099033713340759
step 1902, loss: 0.43167996406555176
step 2488, loss: 0.3818066716194153
step 2844, loss: 0.3411324620246887
step 2903, loss: 0.28981706500053406
step 3635, loss: 0.25954240560531616
step 4973, loss: 0.2321048229932785
step 5705, loss: 0.20806556940078735
step 6068, loss: 0.18346044421195984
step 6421, loss: 0.16418704390525818
step 6640, loss: 0.14483116567134857
step 7762, loss: 0.1291109323501587
step 8874, loss: 0.10690580308437347
step 9827, loss: 0.09526030719280243
step 10992, loss: 0.08375781774520874
step 12286, loss: 0.06789586693048477
step 15354, loss: 0.05798150599002838
step 15638, loss: 0.044690441340208054
step 20540, loss: 0.03738173097372055
step 22693, loss: 0.030900293961167336
step 26052, loss: 0.024779578670859337
step 27163, loss: 0.016678521409630775
step 0, loss: 2.3783857822418213
step 0, loss: 2.4061591625213623
step 0, loss: 2.4047811031341553
step 33, loss: 2.141542911529541
step 65, loss: 1.9170950651168823
step 130, loss: 1.688820719718933
step 0, loss: 2.454932689666748
step 0, loss: 2.42948317527771
step 31, loss: 2.1583213806152344
step 0, loss: 2.464883327484131
step 18, loss: 2.1969730854034424
step 55, loss: 1.9662895202636719
step 90, loss: 1.7330405712127686
step 219, loss: 1.5346589088439941
step 402, loss: 1.3649834394454956
step 537, loss: 1.2083698511123657
step 0, loss: 2.3770956993103027
step 0, loss: 2.440293788909912
step 0, loss: 2.4404454231262207
step 3, loss: 2.1836190223693848
step 8, loss: 1.869319200515747
step 41, loss: 1.6086169481277466
step 90, loss: 1.4126405715942383
step 149, loss: 1.2302300930023193
step 223, loss: 1.0609873533248901
step 0, loss: 2.4621105194091797
step 3, loss: 2.1454033851623535
step 11, loss: 1.8989204168319702
step 46, loss: 1.6791528463363647
step 104, loss: 1.5074787139892578
step 171, loss: 1.341597557067871
step 260, loss: 1.2053278684616089
step 354, loss: 1.0499836206436157
step 439, loss: 0.9321180582046509
step 602, loss: 0.838374674320221
step 784, loss: 0.7437480092048645
step 1023, loss: 0.6620101928710938
step 1379, loss: 0.5598531365394592
step 1931, loss: 0.4624577462673187
step 2508, loss: 0.412784218788147
step 2963, loss: 0.3664316236972809
step 3463, loss: 0.32620471715927124
step 4351, loss: 0.2867359519004822
step 4856, loss: 0.2431984543800354
step 6601, loss: 0.2167591154575348
step 8346, loss: 0.1949722319841385
step 9305, loss: 0.16310469806194305
step 14069, loss: 0.1386570930480957
step 14223, loss: 0.11668972671031952
step 16509, loss: 0.10454455763101578
step 17186, loss: 0.08192822337150574
step 18778, loss: 0.0727444514632225
step 18891, loss: 0.06001010909676552
step 20251, loss: 0.052328407764434814
step 21706, loss: 0.04630254954099655
step 23865, loss: 0.03614230453968048
step 26021, loss: 0.03202880173921585
step 0, loss: 2.4022376537323
step 3, loss: 2.1522908210754395
step 15, loss: 1.9159787893295288
step 48, loss: 1.7077420949935913
step 80, loss: 1.5232383012771606
step 165, loss: 1.3707304000854492
step 221, loss: 1.2335561513900757
step 279, loss: 1.108737587928772
step 351, loss: 0.9846908450126648
step 520, loss: 0.8450294137001038
step 689, loss: 0.7143511772155762
step 1079, loss: 0.6427416205406189
step 1202, loss: 0.562915563583374
step 1527, loss: 0.49982011318206787
step 2000, loss: 0.41828009486198425
step 2445, loss: 0.3730301558971405
step 2929, loss: 0.3347606062889099
step 3305, loss: 0.2869243621826172
step 4150, loss: 0.24812911450862885
step 4588, loss: 0.21699212491512299
step 5616, loss: 0.17354722321033478
step 6956, loss: 0.1560727059841156
step 7187, loss: 0.1281723976135254
step 7206, loss: 0.11269278824329376
step 8818, loss: 0.1013231948018074
step 9559, loss: 0.09018203616142273
step 11120, loss: 0.07464437186717987
step 12764, loss: 0.06551805138587952
step 12912, loss: 0.05458898842334747
step 13255, loss: 0.04703748971223831
step 14887, loss: 0.04167152941226959
step 0, loss: 2.3255558013916016
step 4, loss: 2.0456249713897705
step 11, loss: 1.8095277547836304
step 0, loss: 2.221149444580078
step 5, loss: 1.9691531658172607
step 53, loss: 1.7254542112350464
step 0, loss: 2.318377733230591
step 5, loss: 1.9779467582702637
step 0, loss: 2.357896327972412
step 4, loss: 1.8980522155761719
step 80, loss: 1.6906208992004395
step 110, loss: 1.5209529399871826
step 0, loss: 2.4760537147521973
step 3, loss: 2.2216806411743164
step 4, loss: 1.9467116594314575
step 16, loss: 1.7018773555755615
step 70, loss: 1.5222296714782715
step 158, loss: 1.3209989070892334
step 196, loss: 1.1290324926376343
step 393, loss: 1.0122400522232056
step 442, loss: 0.882605791091919
step 690, loss: 0.7817625403404236
step 893, loss: 0.6939462423324585
step 0, loss: 2.263413906097412
step 5, loss: 1.8953256607055664
step 19, loss: 1.682361125946045
step 52, loss: 1.501073956489563
step 68, loss: 1.278102159500122
step 1063, loss: 0.5947179198265076
step 135, loss: 1.1318702697753906
step 166, loss: 0.980276882648468
step 218, loss: 0.8271524906158447
step 339, loss: 0.6569437384605408
step 1536, loss: 0.5341999530792236
step 518, loss: 0.5695323944091797
step 675, loss: 0.5111287236213684
step 865, loss: 0.4153551757335663
step 1218, loss: 0.36270344257354736
step 1311, loss: 0.2721298635005951
step 2942, loss: 0.466267853975296
step 1920, loss: 0.24277593195438385
step 3001, loss: 0.18197666108608246
step 3432, loss: 0.15397222340106964
step 4245, loss: 0.13681650161743164
step 6010, loss: 0.4010764956474304
step 5087, loss: 0.12196247279644012
step 5202, loss: 0.10142742097377777
step 6897, loss: 0.09106524288654327
step 7146, loss: 0.06180482730269432
step 11712, loss: 0.3411000072956085
step 11715, loss: 0.295172780752182
step 11721, loss: 0.19422507286071777
step 11730, loss: 0.15234296023845673
step 11735, loss: 0.11950159817934036
step 11753, loss: 0.10645508766174316
step 11761, loss: 0.0739295706152916
step 11809, loss: 0.04916707053780556
step 10468, loss: 0.049766529351472855
step 11916, loss: 0.03941977396607399
step 11996, loss: 0.029709741473197937
step 12068, loss: 0.02527683414518833
step 12123, loss: 0.019516801461577415
step 12410, loss: 0.017121775075793266
step 12669, loss: 0.014709725975990295
step 12887, loss: 0.01237757783383131
step 13053, loss: 0.009975138120353222
step 11812, loss: 0.04278967157006264
step 13268, loss: 0.008974188938736916
step 11929, loss: 0.03718822821974754
step 11958, loss: 0.029888037592172623
step 12101, loss: 0.02684556506574154
step 13918, loss: 0.007017582654953003
step 12534, loss: 0.017081033438444138
step 12783, loss: 0.014642711728811264
step 12809, loss: 0.012506763450801373
step 14505, loss: 0.00630721403285861
step 13496, loss: 0.009794776327908039
step 15182, loss: 0.0052225347608327866
step 13919, loss: 0.008124852553009987
step 14705, loss: 0.0062881046906113625
step 16707, loss: 0.0039808074943721294
step 16661, loss: 0.004921943414956331
step 19013, loss: 0.003590128617361188
step 20880, loss: 0.003099979367107153
step 21633, loss: 0.002742930082604289
step 21805, loss: 0.0015767712611705065
step 21318, loss: 0.0032070644665509462
step 0, loss: 2.0709919929504395
step 45, loss: 1.7829443216323853
step 94, loss: 1.5699375867843628
step 123, loss: 1.3741698265075684
step 159, loss: 1.202509880065918
step 168, loss: 1.0371028184890747
step 0, loss: 2.292938470840454
step 5, loss: 1.9581695795059204
step 34, loss: 1.6610844135284424
step 789, loss: 0.9129418134689331
step 845, loss: 0.7946159243583679
step 855, loss: 0.7138421535491943
step 0, loss: 2.185028314590454
step 6, loss: 1.928351879119873
step 15, loss: 1.7130993604660034
step 0, loss: 2.263787031173706
step 14, loss: 2.0246455669403076
step 26, loss: 1.770552158355713
step 0, loss: 2.2428910732269287
step 0, loss: 2.254119634628296
step 8, loss: 2.009120464324951
step 15, loss: 1.795432448387146
step 27, loss: 1.6089019775390625
step 54, loss: 1.4450888633728027
step 82, loss: 1.2655327320098877
step 0, loss: 2.2614567279815674
step 6, loss: 2.0313327312469482
step 11, loss: 1.819976806640625
step 34, loss: 1.6371479034423828
step 47, loss: 1.4657866954803467
step 74, loss: 1.2888870239257812
step 115, loss: 1.1332498788833618
step 158, loss: 1.0179542303085327
step 189, loss: 0.9016087651252747
step 228, loss: 0.7828602194786072
step 291, loss: 0.6935120224952698
step 353, loss: 0.6225147247314453
step 382, loss: 0.5559046864509583
step 460, loss: 0.49583372473716736
step 521, loss: 0.40967971086502075
step 751, loss: 0.3581797182559967
step 867, loss: 0.31489670276641846
step 957, loss: 0.266777902841568
step 274, loss: 0.2396976500749588
step 571, loss: 0.21215786039829254
step 11, loss: 0.18912966549396515
step 164, loss: 0.15811555087566376
step 46, loss: 0.14149808883666992
step 65, loss: 0.12454768270254135
step 129, loss: 0.0915130153298378
step 209, loss: 0.07567881047725677
step 600, loss: 0.06756287813186646
step 623, loss: 0.059267815202474594
step 910, loss: 0.04636337235569954
step 913, loss: 0.0394035242497921
step 0, loss: 2.5835020542144775
step 3, loss: 2.2742562294006348
step 9, loss: 2.0290908813476562
step 38, loss: 1.8213756084442139
step 73, loss: 1.6104310750961304
step 145, loss: 1.4363442659378052
step 204, loss: 1.286944031715393
step 234, loss: 1.1493823528289795
step 294, loss: 1.0193809270858765
step 341, loss: 0.8988715410232544
step 401, loss: 0.790348470211029
step 491, loss: 0.7070956826210022
step 514, loss: 0.6277565956115723
step 661, loss: 0.5447779297828674
step 753, loss: 0.47469013929367065
step 930, loss: 0.40714237093925476
